version: '3.8'

services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_DB: airflow,airflow_meta
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      # Add these lines for CDC:
      POSTGRES_INITDB_ARGS: "-E UTF8 --lc-collate=C --lc-ctype=C"
      POSTGRES_HOST_AUTH_METHOD: "trust"  # For simplicity (adjust for production)
    command:
      - "postgres"
      - "-c"
      - "wal_level=logical"  # Enable logical replication
    ports:
      - "5435:5432"
    networks:
      - networkPFE
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db:/docker-entrypoint-initdb.d
      - ./postgres-csv:/postgres-csv
#      - ./data/synthetic:/data/synthetic

    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow", "-d", "airflow"]
      interval: 10s
      retries: 5
      start_period: 10s
      timeout: 5s


  airflow-scheduler:
    image: apache/airflow:2.9.2
    container_name: airflow-scheduler
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow_meta
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    volumes:
      - E:\flavor-trend-flink-processor\dags:/opt/airflow/dags
      - /var/run/docker.sock:/var/run/docker.sock
      - E:\flavor-trend-flink-processor\ml:/opt/airflow/scripts/ml
    networks:
      - networkPFE
    command: scheduler
    healthcheck:
      test: [ "CMD", "airflow", "jobs", "check", "--job-type", "SchedulerJob", "--local" ]
      interval: 30s
      timeout: 10s
      retries: 5

  airflow-webserver:
      build:
        context: .
        dockerfile: airflow.Dockerfile
      container_name: airflow-webserver
      depends_on:
        airflow-scheduler: # <-- Now waits for the scheduler to be healthy
          condition: service_healthy
      environment:
        AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow_meta
        AIRFLOW__CORE__EXECUTOR: LocalExecutor
        AIRFLOW__CORE__LOAD_EXAMPLES: "false"
        AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "true"
        AIRFLOW__DOCKER__HOST: "unix://var/run/docker.sock"
      volumes:
        - E:\flavor-trend-flink-processor\dags:/opt/airflow/dags
        - /var/run/docker.sock:/var/run/docker.sock
        - E:\flavor-trend-flink-processor\ml:/opt/airflow/scripts/ml
      ports:
        - "8080:8080"
      networks:
        - networkPFE
      command: bash -c "airflow db upgrade && airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true && airflow webserver"

  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - networkPFE

  kafka:
    image: confluentinc/cp-kafka:7.6.1
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "9092:9092"
      - "9093:9093"
    healthcheck:
      test: nc -z localhost 9092 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - networkPFE

  control-center:
    image: confluentinc/cp-enterprise-control-center:7.4.0
    hostname: control-center
    container_name: control-center
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:9092'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      CONFLUENT_METRICS_ENABLE: 'false'
      PORT: 9021
    networks:
      - networkPFE
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9021/health" ]
      interval: 30s
      timeout: 10s
      retries: 5

  debezium-ui:
    image: debezium/debezium-ui:latest
    container_name: debezium-ui
    hostname: debezium-ui
    depends_on:
      kafka-connect:
        condition: service_healthy
    ports:
      - '8086:8080'
    environment:
      KAFKA_CONNECT_URIS: http://kafka-connect:8083

    networks:
      - networkPFE


  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.6.1
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_REST_PORT: 8083
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_CONFIG_STORAGE_TOPIC: "connect-configs"
      CONNECT_OFFSET_STORAGE_TOPIC: "connect-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "connect-status"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_PLUGIN_PATH: "/usr/share/java"
    ports:
      - "8085:8083"
    volumes:
      - "E:/flavor-trend-streamsPFE/debezium-connector-postgres-2.5.0.Final-plugin/debezium-connector-postgres:/usr/share/java/debezium-connector-postgres"
      - kafka_connect_data:/kafka/connect
    networks:
      - networkPFE

    restart: always
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8083/connectors"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s

  jobmanager:
#    image: flink:1.18
    build:
      context: ../flavor-trend-flink-processor
      dockerfile: Dockerfile
    container_name: jobmanager
    ports:
      - "8082:8081"
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        python.fn-execution.memory.managed: true         # <-- ADD THIS
        python.fn-execution.framework.memory.size: 256mb  # <-- ADD THIS
        python.fn-execution.task.memory.size: 512mb       # <-- ADD THIS
      - MLFLOW_TRACKING_URI=http://host.docker.internal:5000
    networks:
      - networkPFE
    volumes:
      - E:\flavor-trend-flink-processor:/opt/flink/project

  taskmanager:
    build:
      context: ../flavor-trend-flink-processor
      dockerfile: Dockerfile
    depends_on:
      - jobmanager
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 8
        taskmanager.memory.framework.off-heap.size: 256mb
        python.fn-execution.memory.managed: true        # <-- ADD THIS
        python.fn-execution.framework.memory.size: 256mb  # <-- ADD THIS
        python.fn-execution.task.memory.size: 512mb       # <-- ADD THIS
      - MLFLOW_TRACKING_URI=http://host.docker.internal:5000
    networks:
      - networkPFE
    volumes:
      - E:\flavor-trend-flink-processor:/opt/flink/project

  superset:
    image: apache/superset:2.1.3
    container_name: superset
    depends_on:
      - postgres
    environment:
      SUPERSET_SECRET_KEY: 'change_this_to_a_strong_random_string'
      SUPERSET_DATABASE_URI: 'sqlite:////app/superset_home/superset.db'
      MAPBOX_API_KEY: "pk.eyJ1IjoibWFobW91ZGdyaWJlaiIsImEiOiJjbWFyM2s0OTYwMW4yMmpzaGk1dXBnZTI4In0.0kckKejtizS8Hl2J6y4iuQ"
    ports:
      - "8088:8088"
    volumes:
      - superset_home:/app/superset_home
    networks:
      - networkPFE

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.14.1
    container_name: mlflow
    depends_on:
      - postgres
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=postgresql://airflow:airflow@postgres:5432/airflow
      - MLFLOW_ARTIFACTS_DESTINATION=/mlflow/artifacts
      - MLFLOW_SERVE_ARTIFACTS=true
    volumes:
      - mlflow_data:/mlflow/artifacts
    networks:
      - networkPFE
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri ${MLFLOW_BACKEND_STORE_URI}
      --artifacts-destination ${MLFLOW_ARTIFACTS_DESTINATION}
      --serve-artifacts
    

volumes:
  postgres_data:
  airflow_logs:
  kafka_data:
  kafka_connect_data:
  superset_home:
  mlflow_data:

networks:
  networkPFE:
    driver: bridge
